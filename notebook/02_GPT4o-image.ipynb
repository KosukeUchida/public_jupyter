{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT4oを用いた画像処理について試す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概要\n",
    "\n",
    "GPT4oを用いて画像処理を行う方法を試し、どのような活用方法が考えられるかを考察する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 事前準備\n",
    "\n",
    "1. 以下公式よりAzureOpenAIリソースを作成し、GPT4oのモデルをデプロイし使用可能な状態とする。\n",
    "    - [Azure OpenAIリソースの作成](https://learn.microsoft.com/ja-jp/azure/ai-services/openai/how-to/create-resource?pivots=web-portal)\n",
    "2. .envファイルを作成する。\n",
    "\n",
    "    ```\n",
    "    cp .devcontainer/.env.example .devcontainer/.env\n",
    "    ```\n",
    "\n",
    "3. .envファイルの下記項目に適切な値を記述する。\n",
    "\n",
    "    ```\n",
    "    OPENAI_API_KEY=xxxxxxxx\n",
    "    OPENAI_API_BASE=https://{resource name}.openai.azure.com/\n",
    "    OPENAI_API_VERSION=2024-02-01\n",
    "    OPENAI_DEPLOYMENT_NAME_GPT4o={deployment name}\n",
    "    ```\n",
    "\n",
    "4. Devcontainerを起動する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.40.6-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/site-packages (from openai) (2.8.2)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Downloading openai-1.40.6-py3-none-any.whl (361 kB)\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading jiter-0.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: tqdm, sniffio, jiter, h11, distro, httpcore, anyio, httpx, openai\n",
      "Successfully installed anyio-4.4.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.40.6 sniffio-1.3.1 tqdm-4.66.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "AZURE_OPENAI_ENDPOINT = os.environ.get('OPENAI_API_BASE')\n",
    "DEPLOYMENT_NAME = os.environ.get('OPENAI_DEPLOYMENT_NAME_GPT4o')\n",
    "API_VERSION = os.environ.get('OPENAI_API_VERSION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "参考：[公式サンプルコード](https://learn.microsoft.com/ja-jp/azure/ai-services/openai/gpt-v-quickstart?tabs=image%2Ccommand-line&pivots=programming-language-python#create-a-new-python-application)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "def gptImageAnalysis(userMessage :str, imageUrl :str):\n",
    "    client = AzureOpenAI(\n",
    "        api_key=AZURE_OPENAI_API_KEY,  \n",
    "        api_version=API_VERSION,\n",
    "        base_url=f\"{AZURE_OPENAI_ENDPOINT}/openai/deployments/{DEPLOYMENT_NAME}\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=DEPLOYMENT_NAME,\n",
    "        messages=[\n",
    "            { \"role\": \"system\", \"content\": \"You are a helpful assistant. Please output in Japanese.\" },\n",
    "            { \"role\": \"user\", \"content\": [  \n",
    "                { \n",
    "                    \"type\": \"text\", \n",
    "                    \"text\": userMessage \n",
    "                },\n",
    "                { \n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": imageUrl\n",
    "                    }\n",
    "                }\n",
    "            ] } \n",
    "        ],\n",
    "        # max_tokens=2000 　GPT4oはデフォルト4096の為指定不要\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "def getOutputMessage(response):\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試しに上記の公式サンプルコードにあった画像を使用  \n",
    "![](https://learn.microsoft.com/ja-jp/azure/ai-services/openai/media/quickstarts/endpoint.png#lightbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "この画像は、Microsoft Azureポータルの「Keys and Endpoint」の設定画面を示しています。この画面では、ユーザーがCognitive Service APIのアクセスキーとエンドポイントを管理することができます。\n",
      "\n",
      "画面の主要部分には以下の情報が含まれています：\n",
      "- 「Regenerate Key1」と「Regenerate Key2」のボタンがあり、キーの再生成が可能です。\n",
      "- 「Show Keys」ボタンをクリックすると、キーの内容を表示します。\n",
      "- 「KEY 1」と「KEY 2」にはAPIのアクセスキーが表示され、セキュリティのために隠されています。\n",
      "- 「Location/Region」セクションでは、「eastus」リージョンが指定されています。\n",
      "- エンドポイントのURLが「https://docs-test-001.openai.azure.com/」として表示されています。\n",
      "\n",
      "左側のナビゲーションメニューには以下の項目があります：\n",
      "- 概要 (Overview)\n",
      "- アクティビティ ログ (Activity log)\n",
      "- アクセス制御 (IAM) (Access control (IAM))\n",
      "- タグ (Tags)\n",
      "- 問題の診断と解決 (Diagnose and solve problems)\n",
      "- リソース管理 (Resource Management): この中に「Keys and Endpoint」が強調表示されています。\n",
      "- その他の項目として、デプロイの管理 (Deployments)、価格設定レベル (Pricing tier)、ネットワーキング (Networking)、ID 管理 (Identity)、コスト分析 (Cost analysis)、プロパティ (Properties)、ロック (Locks) などがあります。\n",
      "\n",
      "この画面は、ユーザーがAzure Cognitive Servicesのアクセス設定を安全に管理できるように設計されています。\n"
     ]
    }
   ],
   "source": [
    "message = \"Describe this picture:\"\n",
    "url = 'https://learn.microsoft.com/ja-jp/azure/ai-services/openai/media/quickstarts/endpoint.png#lightbox'\n",
    "response = gptImageAnalysis(message, url)\n",
    "\n",
    "print(getOutputMessage(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URLだけではなく、画像ファイルをBase64に変換し処理することも可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import base64\n",
    "\n",
    "def convertImageURLtoBase64data(url):\n",
    "    # 画像ファイルダウンロード\n",
    "    dst_path = '../data/temp/temp.png'\n",
    "    urllib.request.urlretrieve(url, dst_path)\n",
    "\n",
    "    # base64 エンコード\n",
    "    with open(dst_path, 'rb') as image:\n",
    "        base64_data = base64.b64encode(image.read()).decode('utf-8')\n",
    "\n",
    "    return f\"data:image/jpg;base64,{base64_data}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "この画像はMicrosoft Azureのポータル画面を示しています。特に「docs-test-001」というCognitive Serviceリソースの「Keys and Endpoint」（鍵とエンドポイント）の設定画面です。\n",
      "\n",
      "- 画面の左側にはナビゲーションメニューがあり、「Resource Management」（リソース管理）の一部として「Keys and Endpoint」が選択されています。\n",
      "- 右側のメインコンテンツには、APIキーとエンドポイントの情報が表示されています。\n",
      "  - 「KEY 1」と「KEY 2」の2つのキーが表示されていますが、実際のキーの内容は隠されています。\n",
      "  - 「Location/Region」（場所/地域）は「eastus」に設定されています。\n",
      "  - エンドポイントは「https://docs-test-001.openai.azure.com/」と記載されています。\n",
      "- また、画面の上部には「Regenerate Key1」と「Regenerate Key2」というキーの再生成オプションがあります。\n",
      "- 情報ボックスには、これらのキーがCognitive Service APIにアクセスするために使用される旨、およびキーのセキュリティと定期的な再生成の推奨事項が記載されています。\n",
      "\n",
      "この設定画面は、Azure Cognitive ServiceのAPIエンドポイントやアクセスキーを管理するためのものです。\n"
     ]
    }
   ],
   "source": [
    "url = 'https://learn.microsoft.com/ja-jp/azure/ai-services/openai/media/quickstarts/endpoint.png#lightbox'\n",
    "\n",
    "base64_image_data = convertImageURLtoBase64data(url)\n",
    "response = gptImageAnalysis(message, base64_image_data)\n",
    "\n",
    "print(getOutputMessage(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "### 01.グラフ情報の読み取り"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
